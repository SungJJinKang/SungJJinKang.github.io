---
layout: post
title:  "IO 시스템 ( 번역 )"
date:   2021-09-26
categories: ComputerScience
---

CPU, GPU, 메모리를 다루면서 어찌보면 마법처럼 이루어져보이는 IO에 대해 공부해야겠다는 생각이 들었다.     
특히 최근에 GPU 구조에 대해 공부하면서 어떻게 GPU가 DRAM에 있는 데이터를 CPU의 개입 없이 가져가는지 등 ( DMA라는 것은 알지만 DMA가 어떻게 동작하는지는 모른다 ) 언젠가는 IO에 대해 공부를 해야겠다고 생각하였다.     
IO가 어떻게 작동하는지에 대해 알면 프로그래밍을 하면서 엄청난 도움이 될 것 같아 공부를 하였다.              

이 글에서는 IO 시스템에 대해 알아보려고한다.           
[이 글](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/13_IOSystems.html)을 번역하였다. 오역이나 발번역이 있을 수도 있다.        

-------------------

**전반적인 이해**              

IO 장치들의 관리는 OS에서 가장 중요한 부분이다. IO에 도움을 주는 IO 하부시스템들은 항상 중요했고 변화를 거쳐왔다. ( 현대 컴퓨터에 있는 마이크, 키보드, 마우스, 디스크, USB 디바이스, 네트워크 연결, 오디오 IO 등등.... 수 많은 IO 장치들이 존재한다. )              
IO 하부시스템들은 크게 두가지 트렌드로 나누어진다. 하나는 새롭게 개발된 장치들에도 쉽게 쉽게 적용할 수 있는 표준 인터페이스 유행, 다른 하나는 현존하는 표준 인터페이스들이 쉽게 적용되지 않는 새로운 유형의 장치들의 발전이 그것이다. ( 터치 스크린 같은 것이 기존에는 없던 IO 유형 중 하나이다. )           
**디바이스 드라이버**는 특정 장치나 비슷한 유형의 장치들을 다루기 위해 운영체제에 적용될 수 있는 모듈이다.                



**IO 하드웨어**          

IO 디바이스들은 크게 저장 디바이스, 상호 작용 ( 커뮤니케이션 ), 유저 인터페이스 ( UI ) 등이 있다.            
디바이스들 무선으로 혹은 유선으로 전달되는 시그널들을 통해서 컴퓨터와 소통한다.         
디바이스들은 시리얼, 병렬 포트와 같은 **포트**들로 컴퓨터에 연결된다.      
다양한 장치들을 연결하는 선들의 집합, 묶음을 **버스**라고 부른다.      
버스들은 경합 ( Contention ) 문제를 해결하기 위해 버스를 통해 전달될 수 있는 여러 메세지들의 유형, 절차들에 대한 엄격한 프로토콜을 가지고 있다.    
아래의 사진을 보면 현대 컴퓨터에서 볼 수 있는 4가지 유형의 버스들 중 3가지 유형을 볼 수 있다.        
- **PCI 버스**는 빠르게 동작하고 높은 대역폭을 가진 장치들을 메모리 하부시스템, CPU에 연결한다. ( GPU를 생각하면 된다. )             
- **Expansion 버스**는 한번에 하나의 문자를 전달하는 것과 같은 조금은 느리고 낮은 대역폭을 가진 장치를 연결한다.           
- **SCSI 버스**는 많은 SCSI 장치들을 SCSI 컨트롤러와 연결시켜준다.     

![g](https://user-images.githubusercontent.com/33873804/134779033-16b9548f-2984-4485-b04b-c25f84d953da.jpg)             

장치들과 소통하는 방법 중 하나는 각각의 포트와 연관된 **레지스터**를 이용하는 것이다. 레지스터들은 1에서 4바이트 정도의 크리고 일반적으로 4가지 종류가 있다.      
- 첫번째로는 **data-in 레지스터**는 장치로부터 입력을 얻기위해 호스트에 읽혀진다.          
- 두번째로는 **data-out 레지스터**로 출력을 전송하기 위해서 호스트에 의해 쓰여 ( write )진다.          
- 세번째로는 **status ( 상태 ) 레지스터**로 input, busy, error, transaction 완료 등에 대한 idle, ready와 같은 장치의 상태를 명시하기 위해 호스트에 의해 읽혀지는 비트들을 가지고 있다.               
- 마지막으로 **control 레지스터**는 패리티 체크, 워드 길이, 전이중 이중 통신과 같은 장치의 설정을 바꾸거나, 커맨드들을 발행하기 위해서 호스트에 의해 쓰여 ( write )지는 비트들을 가지고 있다.          

장치들과 소통하기 위한 또다른 방법으로는 **메모리 맵 IO ( memory-mapped IO )**가 있다.            
- 이 경우 CPU의 주소 공간 중 일부분이 장치에 맵되고 그 메모리 주소 공간에 쓰여거나, 읽어서 소통할 수 있다.           
- 메모리 맵 IO는 그래픽 카드와 같이 많은 양의 데이터를 전송해야하는 장치들에 적합하다.      
- 메모리 맵 IO는 일반적인 레지스터들과 함께 사용될 수도 있고 그것들 대신 사용될 수도 있다.          
- 메모리 맵 IO는 잠재적인 문제를 가지고 있는데, 만약 한 프로그램이 메모리 맵된 IO 장치에 의해 사용되고 있는 주소 공간에 직접적으로 쓰게 되면 문제가 발생한다.   
- ( 메모리 맵 IO는 직접 메모리 접근, DMA와는 다른 것이다. )            


**시스템콜**         

CPU가 A라는 프로그램을 실행하다가 파일을 읽어야할 경우에는 어떤식으로 작업이 이뤄질까? 파일을 읽어오기 위해서는 ( Disk에 접근한다면 Disk Controller에게 명령을 통해서 ) I/O에 접근을 해야하는데, 그러기 위해선 '특권명령 ( 커널 모드 명령어 )'이 필요하다. CPU에서 I/O에 접근하는 명령은 모두 특권명령으로 묶여있다.                     

그런데 실행하고 있던 A라는 프로그램이 사용자프로그램이라면? 무슨 방법으로 I/O에 접근할 수 있을까? 이 때는 특권명령을 사용하기 위해 '운영체제'에게 CPU 사용권한을 넘겨줘야 한다. 이를 '시스템콜'이라고 부른다.     

"사용자 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출하는 것"이라고 이해하면 된다.          

이런 작업을 위해서는 메모리 공간에서의 '점프'가 필요하다. 하나의 프로그램 내에서 작업 순서가 바뀌는 것과는 달리 다른 프로그램(사용자 프로그램에서 운영체제로의)으로 이동하는 것은 다르기 때문이다. 그렇다면 CPU사용권을 어떻게 운영체제로 넘길 수 있을까?             

이전 시간에 배운대로 Interrupt를 활용하면 된다. CPU는 하나의 작업을 마치고 항상 Interrput를 확인하기 때문이다. 그러면 이때 Interrput는 누가 요청하는 것일까?              

시스템콜: 운영체제의 권한이 필요한 사용자 프로그램 스스로가 기계어를 통해 CPU에게 요청      

간단하게 요약하자면 "나 운영체제의 권한이 필요하니까 CPU사용권 좀 운영체제한테 넘겨줘!"라고 요청하는 것과 같다.         


**폴링**             

디바이스 **핸드셰이킹**의 수단들 중 하나이다.     
- 호스드는 디바이스에 있는 **busy 비트**를 반복적으로 체크한다. 이는 busy 비트가 clear될 때까지 반복한다.         
- busy 비트가 clear가 되면 호스트는 데이터 중 1 바이트를 data out 레지스터에 쓴다. 그리고 커맨드 레지스터에 **write 비트**를 설정한다.       
- 호스트는 디바이스에 대기 중인 커맨드를 알리기 위해 커맨드 레지스터에 **커맨드 ready 비트**를 쓴다.             
- 디바이스 컨트롤러가 커맨드 ready 비트가 쓰여진 것을 보면 먼저 busy 비트를 설정한다.       
- 그 후 디바이스 컨트롤러는 커맨드 레지스터를 읽고 write 비트가 설정된 것을 보고, data-out 레지스터로부터 데이터 중 일부를 읽고 그 데이터를 출력한다.           
디바이스 컨트롤러는 상태 레지스터에 있는 **error 비트**, command-ready 비트를 지우고 마지막으로 busy 비트를 지움으로서 동작의 완료를 알린다. ( 시그널링 )            

폴링은 그 장치와 컨트롤러가 빠르고, 전송할 중요한 데이터가 있다면 매우 빠르고 효율적이다. 그러나 만약 호스트가 busy 루프에서 오랫동안 장치를 기다려야하거나 ( busy 비트를 반복적으로 체크하는 것을 말하는 것 같다. ), 드물게 전송하는 데이터를 위해서도 반복적인 busy bit 검사가 필요하기 때문에 비효율적일 수도 있다.                



**인터럽트 ( Interrupts )**              

인터럽트는 CPU가 다른 일을 할 수 있게하기 해주면서 장치가 CPU의 즉각적인 응답이 필요 없는 데이터 전송이 있거나, 진행중이던 동작이 끝났음을 CPU에게 알릴 수 있게 해주는다.         
CPU는 CPU에 의해 매 명령어 후 검사되는 **인터럽트-request line**을 가지고 있다.           
- 디바이스 컨트롤러는 인터럽트 request line에 신호를 보냄으로서 인터럽트를 발생시킨다.         
- 그럼 CPU는 현재 상태를 잠시 저장하고, 메모리 내에 어떤 특정 주소에 있는 **인터럽트 핸들러** 루틴에 제어권을 넘긴다. ( CPU는 인터럽트를 **캐치**하고 인터럽트 핸들러에게 전달한다. )            
- 인터럽트 핸들러는 인터럽트의 원인을 파악하고, 필요한 동작을 수행한 후, 상태를 복구시킨 후, CPU에 제어권을 되돌려주기 위해 **인터럽트에서 복귀** 명령어를 실행한다. ( 인터럽트 핸들러는 장치를 위한 동작을 수행함으로서 인터럽트를 **clear**한다. )                   
- ( 복구된 상태가 인터럽트 이전과 같을 필요는 없다. )      

아래 사진은 인터럽트를 통한 IO의 절차를 보여준다.     
![13_03_Interrupt_IO](https://user-images.githubusercontent.com/33873804/134780459-295f8167-78fa-401a-a2e1-a25cfe120274.jpg)            

위의 사진은 간단한 인터럽트를 통한 IO에 대해 잘 묘사하고 있지만, 현대 컴퓨팅에는 위의 사진을 더 복잡하게 만드는 세가지 요소가 있다.      
- 하나는 중요한 동작 동안에는 인터럽트 핸들링을 잠시 지연시킬 필요성.                               
- 다른 하나는 모든 장치들에 대해 폴링을 하지 않기 위해 인터럽트 핸들러가 실행하거나 주의를 기울어야할 장치를 결정할 필요성.             
- 마지막으로 멀티 레벨 인터럽트인데, 이는 인터럽트의 우선 순위에 따라 시스템이 적절한 응답을 하기 위함이다.       

이러한 문제들은 현대 컴퓨터 아키텍쳐에서 **인터럽트 컨트롤러**를 통해 해결할 수 있다.                                          
- 오늘날 대부분의 CPU들은 두가지 인터럽트-request line을 가지고 있다. 하나는 중요한 에러를 다루는 **non-maskable**, 다른 하나는 CPU가 중요한 동작을 하는 동안에는 CPU가 잠시 무시할 수 있는 **maskable**이 그것이다.      
- 인터럽트 메커니즘는 **인터럽트 vector**라고 불리는 어떤 테이블의 오프셋으로 사용되는 수들의 작은 집합인 **address**를 받는다.       
- 활용 가능한 인터럽트 핸들러의 수는 여전히 정의된 인터럽트의 수를 초과한다. 그래서 여러 인터럽트들은 **인터럽트 chained**될 수 있다. 인터럽트 vector들의 주소들은 인터럽트 핸들러들의 링크드 리스트들에 대한 head 포인터들이다. ( 그러니깐 인터럽트 핸들러는 일종의 주소를 받는데 이 주소는 인터럽트 핸들러의 위치 주소를 가지고 있는 인터럽트 vector의 index로 사용된다. )            
- 현대 인터럽트 하드웨어는 또한 **인터럽트 우선순위 단계**를 지원한다. 이는 높은 우선 순위를 가진 인터럽트를 처리하는 동안에는 낮은 우선 순위의 인터럽트를 무시할 수 있게 해주고, 낮은 우선 순위의 인터럽트를 처리하는 것을 인터럽트하여 높은 순위 인터럽트를 우선 처리하게 해준다.                 

컴퓨터를 키면 시스템은 어떤 장치들이 있는지 확인하고 인터럽트 테이블에 적절한 인터럽트 핸들러 주소를 저장한다.             
동작하는 동안 디바이스들은 인터럽트를 통해 커맨드의 처리 완료나, 에러들을 알린다 ( 시그널링 한다. )             
분모가 0인 나누기, 잘못된 메모리 접근, 커널 모드 명령어로의 접근 시도와 같은 예외들도 인터럽트를 통해서 시그널될 수 있다.          
Time Slicing과 컨테스트 스위칭 또한 인터럽트 메커니즘을 통해 구현할 수 있다.       
- 스케줄러는 유저 프로세스에 제어권을 넘기기 전에 하드웨어 타이머를 설정한다. ( 일정 시간 후 다시 스케줄러가 제어권을 가지고 스케줄러를 하기 위함 )              
- 타이머가 인터럽트 request line에 인터럽트를 발생시키면 CPU는 상태 저장을 하고, 적절한 인터럽트 핸들러에 제어권을 넘긴다. 이는 스케줄러를 동작시킨다.          
- 스케줄러는 타이머를 초기화하고, 인터럽트에서 복귀 명령어를 만들기 전 다양한 프로세서들의 상태 복구를 한다.            
비슷한 예로는 가상 메모리 페이징 시스템이 있다. 페이지 폴트는 인터럽트를 발생시키는데 이는 결국 위에서 설명한대로 IO 요청, 컨테스트 스위치로 이어진다. 이후 인터럽트 된 프로세스를 대기 큐에 넣고, 동작할 다른 어떤 프로세스를 선택한다. ( 그러니깐 페이지 폴트로 페이지를 다시 가져오라는 IO를 요청한 후  CPU는 페이지를 가져오는 것을 기다리고 있지 않고 컨테스트 스위치를 하여 다른 프로세스를 실행하고 있는다. ) ( IO 요청 후 CPU가 무엇을 할지는 스케줄링 알고리즘, 정책에 따라 다르다. )                   
시스템 콜들은 **트랩**이라고 불리는 **소프트웨어 인터럽트**를 통해 구현될 수 있다. 프로그램 ( 유저 모드 )이 커널 모드에서 실행될 필요가 있는 동작이 필요할 때, 프로그램은 커맨드 정보와 수행할 데이터의 주소를 특정 레지스터에 쓴다. 그 후 소프트웨어 인터럽트를 발생시킨다. 시스템은 상태를 저장하고 커널모드에서 유저 모드로부터 받은 요청을 처리하기 위해 적절한 인터럽트 핸들러를 호출한다. ( 유저 모드 프로그램이 커널 모드 권한을 사용하기 위해 인터럽트를 활용하는 것이다 ) 소프트웨어 인터럽트들은 대개 낮은 우선순위를 가지는데, 이는 이 소프트웨어 인터럽트들이 한정된 버퍼링 공간을 가진 디바이스들의 인터럽트 같이 급하게 처리해야하지는 않기 때문이다. ( 버퍼링 공간이 한정되면 그 버퍼링 공간이 다 차기 전 얼른 해당 버퍼링 공간을 처리해주어야 한다. )                       
또한 인터럽트는 커널 동작을 제어하기 위해서도 사용되고, 최적의 성능을 위해 동작들을 스케줄하기 위해서 사용된다. 예를 들면, 디스크의 "읽기 동작 완료"는 두 가지 인터럽트를 발생시킨다.       
- 하나는 높은 우선 순위 인터럽트로 장치의 완료를 알리고, 하드웨어가 idle 상태에 빠져있지 않게 만들기 위해 다음으로 처리할 디스크 요청을 전송하는 것이다.            
- 다른 하나는 낮은 우선 순위 인터럽트로 커널 메모리 공간에서 유저 공간으로 데이터를 전송하고, 대기 큐에서 준비 큐로 프로세스를 전송한다.           
Solaris OS는 멀티 스레드 커널을 사용하고 다양한 인터럽트 핸들러들에게 다양한 쓰레드를 배정하는 스레드를 우선 순위로 둔다. 이는 다양한 인터럽트들에 대한 "동시성" 핸들링을 하게 해주고, 높은 우선 순위 인터럽트들이 낮은 우선 순위 인터럽트, 유저 프로세스들보다 우선 처리되게 보장한다.         
 


**직접 메모리 접근 ( Direct Memory Access )**                 

디스크 컨트롤러와 같은 대량의 데이터를 전송하는 장치들에게는, CPU가 한번에 한 바이트씩 레지스터로/로부터 데이터를 전송하게 제한하는 것은 매우 자원을 낭비하는 것이다.         
대신 이러한 작업은 **Direct Memory Access, DMA, Controller**로 알려진 특별한 프로세서에 맡길 수 있다.         
호스트는 DMA 컨트롤러로 커맨드를 전송하는데, 이 커맨드는 전송할 데이터의 위치, 데이터가 전송될 위치, 전송할 데이터의 사이즈를 가지고 있다. DMA 컨트롤러는 데이터 전송을 처리하고, 데이터 전송이 끝나면 CPU에 인터럽트를 발생시킨다.         
간단한 DMA 컨트롤러는 거의 모든 현대 PC에서 보편적인 요소이고, 많은 **bus-mastering** IO 카드들은 그들 자신의 DMA 하드웨어를 가지고 있다.       
DMA 컨트롤러들과 그들 장치들 사이의 handshaking은 DMA-request, DMA-acknowlege 라고 불리는 두 선들을 통해 이루어진다.        
DMA 전송이 진행되는 동안 CPU는 PCI-bus에 접근할 수 없지만 ( 당연히 DMA 전송이 PCI 버스로 이루어지고 있기 때문에 ), CPU는 코어의 레지스터, 캐시들에는 접근할 수 있다. ( DMA 전송은 디바이스와 DRAM과의 데이터 전송이니 DMA 전송 동안 CPU는 DRAM말고 레지스터, 캐시들에는 여전히 접근할 수 있다는 것이다. )                
DMA는 피지컬 주소, 피지컬 주소에 매핑된 가상 주소 모두에 적용할 수 있다. 후자의 경우는 **Direct Virtual Memory Access, DVMA**라고 부르고 메인 메모리 칩을 사용하지 않고 하나의 메모리 매핑된 장치에서 다른 장치로 데이터를 직접 전송할 수 있게해준다. ( 메모리 Mapped IO의 메모리들 사이에 데이터 전송이 가능하다는 것 같다. )                 
유저 프로세스들에 의한 직접적인 DMA 접근은 연산을 빠르게하지만, 일반적으로는 보안, 데이터 보호를 이유로 현대 OS에서는 금지되어있다. ( DMA는 커널 모드 동작이다. ) ( 그래서 유저 프로세스는 커널 모드 함수를 호출해서 간접적으로  DMA를 활용한다. )                       

아래 사진은 DMA 처리 과정을 보여준다.     

![13_05_DMA_Transfer](https://user-images.githubusercontent.com/33873804/134782676-a7ffc1a2-57f3-46fb-abff-a0f9f3fbd3ff.jpg)            


추가적인 설명을 덧붙이자면        

CPU는 메모리와만 일할 수 있다.      
CPU가 I/O가 필요할 경우 I/O 디바이스에 존재하는 디바이스 컨트롤러라는 작은 CPU에게 일 시키고 자신은 계속 다음 명령어 실행한다.       
디바이스의 디바이스 컨트롤러가 모든 일 마친 후 디바이스 컨트롤러 내의 로컬 버퍼에 데이터 저장하면 CPU에게 작업을 마친 것을 인터럽트를 통해 알려준다.          
디바이스의 디바이스 컨트롤러는 메모리에 직접 접근을 할 수 없기 때문에 디바이스 컨트롤러가 자신의 로컬 버퍼에 임시로 데이터를 저장해두면 인터럽트를 받은 CPU가 이 디바이스의 로컬 버퍼에 있는 데이터를 메모리로 옮겨야한다.     
이렇게 IO 장치의 인터럽트가 계속해서 많아지면 CPU는 자신의 일을 못하고 매번 IO의 인터럽트에 불러나가야한다.      

그래서 DMA Controller가 사용되는 것이다.            
IO가 작업을 완료 후 IO의 로컬 버퍼에 결과 데이터를 저장하면 DMA가 CPU를 대신하여 IO의 로컬 버퍼의 결과 데이터를 메모리에 옮긴 후 DMA가 다 옮기면 CPU에 인터럽트를 한번만 걸어서 로컬 버퍼의 메모리의 복사 작업이 완료되었음을 알려준다.            
( 여기서 CPU와 DMA가 동시에 메모리에 접근하여 동시에 읽기/쓰기 동작을 하면 안되니 메모리 컨트롤러가 CPU, DMA를 중재한다. )                


**어플리케이션 IO 인터페이스**            
         
다양한 장치로의 유저 어플리케이션 접근은 레이어링, 디바이스용 코드를 **디바이스 드라이버들**에 캡슐화한 후 넣어 이룰 수 있다. 이렇게 디바이스 드라이버들에는 디바이스용 코드가 캡슐화되어 들어가는데 반해 어플리케이션 레이어에서는 모든 ( 최소한 다목적 ) 장치들에 대해 공통된, 범용적인 인터페이스를 가진다.        

아래는 커널 IO 구조를 보여주는 사진이다. ( 커널 IO 시스템이 디바이스 드라이버를 통해 디바이스 컨트롤러와 소통한다. )               
![13_06_Kernel_IO_Structure](https://user-images.githubusercontent.com/33873804/134782830-00263975-87a0-4d2a-a235-c4e4484db29e.jpg)         

아래 사진은 다양한 IO 장치들의 특성을 보여준다.          
![13_07_DeviceCharacteristics](https://user-images.githubusercontent.com/33873804/134782861-6ac784d5-f9f5-4930-a27d-403490c60ea6.jpg)        

대부분 장치들은 블록 IO, 문자 IO, 메모리 맵 파일 접근, 네트워크 소켓으로 분류할 수 있다. 시간, 시스템 타이머와 같은 몇몇 특별한 장치도 있다.      
대부분의 OS들은 필요할 때 어플리케이션이 디바이스 드라이버들로 직접적으로 커맨드들을 보낼 수 있는 **escape**나 **back door**를 가지고 있다.                  

 

**블록, 문자 디바이스들**             

블록 디바이스들은 한번에 한 블록씩 접근하고, UNIX 시스템에서는 긴 리스트 중 첫번째 문자열로 'b'로 시작하는 디바이스들이다. read(), write(), seek()와 같은 연산을 지원한다.            
- 하드 드라이버에 있는 블록들에 직접적으로 접근하는 것은 ( 파일 시스템 구조를 거치지 않고 ) **raw IO**라고 불린다. 이는 OS에 의해 일반적으로 수행되는 locking이나 버퍼링을 거치지 않기 때문에 특정 연산들의 속도를 높여준다. ( 어플리케이션이 직접 locking, 버퍼링을 처리해야한다. )                   
- 새로운 대안으로는 **direct IO**가 있는데 이는 locking, 버퍼링 연산을 제거한 일반적인 파일시스템 접근을 통해 이루어진다.       


메모리 맵 파일 IO는 블록 디바이스 드라이버들 위에 위치할 수 있다.        
- 전체 파일을 읽는 것이 아니라, 특정 메모리 영역에 맵핑되고, 필요하다면 가상 메모리 시스템을 사용하여 메모리를 페이징한다.           
- 파일로의 접근은 read(), write()와 같은 시스템 콜 ( 커널 모드 호출 )들이 아니라 일반적인 메모리 접근들을 통해 이루어질 수 있다. 이러한 접근은 흔히 실행 프로그램 코드에서 사용하는 방법이다.            
**문자 장치들**은 한번에 한 바이트만 접근할 수 있다. 고 수준 라이브러리 루틴들에 의해 지원되는 전체 라인 읽기와 같은 발전한 기능들을 지원하는 get(), put() 연산을 지원한다.                 


**네트워크 디바이스들**       

네트워크 접근은 로컬 디스크 접근과 다르기 때문에 대부분의 시스템은 네트워크 디바이스들을 위한 전용 인터페이스를 제공한다.          
흔하고 널리 사용되는 인터페이스 중 하나는 **소켓** 인터페이스이다. 이 소켓 인터페이스는 두 개의 네트워크 엔티티들을 연결하는 케이블, 파이프라인과 같은 역할을 한다. 데이터는 한쪽 끝의 소켓으로 전송할 수 있고, 다른 쪽 끝에서 차례대로 읽을 수 있다. 소켓들은 일반적으로 전이중 통신이고, 양방향 데이터 전송도 할 수 있게해준다.             
select() 시스템 콜은 서버 ( 다른 어플리케이션들 )가 모든 이용 가능한 소켓들을 폴링하지 않고도 대기 중인 데이터를 가지고 있는 소켓이 어떤 것인지 알려준다.                  


**클록, 타이머**               

세가지 종류의 시간 서비스들이 현대 시스템에서 흔히 사용된다.       
- 현재 시간
- 이전 이벤트 후 경과한 시간
- 타임 T에 이벤트 X를 발동하기 위한 타이머 설정
불행히도 시간 연산은 모든 시스템에 표준으로 존재하지 않는다.       
**프로그래밍이 가능한 인터럽트 타이머, PIT**는 연산을 발동하기 위해 사용될 수 있고, 경과한 시간을 측정하기 위해서도 사용될 수 있다. 미래의 특정 시점에 인터럽트를 발동하기 위해서도 사용될 수 있고, 주기적으로 인터럽트를 발동시키기 위해서도 사용된다.         
- 스케줄러는 타임 slice를 끝내는 인터럽트를 발동시키기 위해 PIT를 사용한다.     
- 디스크 시스템은 디스크로 버퍼를 flush하는 것과 같은 주기적인 버퍼 관리를 스케줄링하기 위해서 PIT를 사용한다.          
- 네트워크들은 완료하는데 오랜 시간이 걸리는 연산을 반복하거나 중단시키기 위해 PIT를 사용한다.      
- 타이머 이벤트들의 순차적 리스트를 관리하거나 다음으로 스케줄된 이벤트가 발생했을 때 물리적 타이머를 꺼지도록 설정하여 실제 존재하는 타이머 개수보다 더 많은 타이머를 구현할 수 있다.             
대부분의 시스템에서 시스템 클록은 PIT에 의해 생성되는 인터럽트의 수를 세는 것으로 구현된다. 불행이도 이는 PIT의 인터럽트 빈도에 비례하게 제한될 수 밖에 없는데 시간이 지남에 따라 문제가 될 수도 있다. 대안으로는 높은 정확도, 정밀도를 가진 고빈도 하드웨어 카운터에 직접적인 접근을 제공하는 것인데, 아쉽게도 이 고빈도 하드웨어 카운터는 인터럽트를 지원하지 않는다. ( 위에서 예시로 보여준 것들에 활용할 수 없다. )                



**블락킹, 논블락킹 IO**                         

**블락킹 IO** 요청이 발생하였을 때 프로세스는 대기 큐로 이동되고, IO 요청이 끝나면 준비 큐로 돌아간다. 한 프로세스가 대기 큐로 이동해 있는 동안에는 다른 프로세스들이 CPU를 점유하고 동작한다.       
**논블록킹 IO** 요청의 경우, 요청된 IO 동작이 ( 완전히 ) 발생하였는지 여부와 관계 없이 IO 요청은 즉각적으로 반환된다. 이를 통해 프로세스는 사용 가능한 데이터가 없는 경우 완전히 대기 상태에 들어가지 않고 ( 데이터를 기다리는 동안 아무 것도 않하고 기다리지 않고 ) 가용 데이터를 확인하게 해준다.    
프로그래머가 논블록킹 IO를 구현하는 방법 중 하나는 멀티 스레드 프로그래밍을 하는 것이다. 이를 통해 한 스레드가 블록킹 IO 호출을하면 ( 그럼 이 스레드는 대기 큐에 들어간다 ), 다른 스레드들이 다른 동작을 수행한다.         
논블록킹 IO의 변형으로는 **비동기 IO**가 있다. 비동기 IO는 즉각적으로 프로세스가 다른 동작을 수행하게 해주고, IO 동작이 끝나고 데이터가 이용 가능해지면 프로세스에게 곧바로 알려준다. ( 프로세스의 변수를 바꾸거나, 소프트웨어 인터럽트, 콜백 함수를 통해 알려준다. ) ( 일반적인 논블록킹 IO 또한 결과 데이터가 이용 가능하든 아니든 즉각적으로 반환을 해주지만, IO 동작이 끝났을 때 알려주지 않는다. )            

아래 사진에서 (a)는 동기성 IO, (b)는 비동기성 io 과정을 보여준다.      
![13_08_Two_IO_Methods](https://user-images.githubusercontent.com/33873804/134784742-adfe2a77-ed2c-4c0c-b4f4-b7538bdc34e4.jpg)            



**커널 IO 하부시스템**            


**IO 스케줄링**          

IO 요청들을 스케줄링하는 것은 전체적인 효율성을 높일 수 있다. 스케줄링 요청에 우선 순위가 사용된다.          
전통적인 예는 디스크 접근의 스케줄링이 그 예이다.         
버퍼링, 캐싱 또한 더욱 유연한 스케줄링 옵션을 가능하게 해준다.           
많은 디바이스들의 시스템에서는 별개의 요청 큐들이 각각의 장치들을 위해 존재한다.         

아래 사진은 디바이스 상태 테이블을 보여준다.        
![13_09_DeviceStatusTable](https://user-images.githubusercontent.com/33873804/134784796-132f2d4c-5980-4318-8e33-99ed9b591b0c.jpg)             

**버퍼링**           
IO의 버퍼링은 주로 3가지 이유로 수행된다.        
- 두 장치간 속도 차이. 느린 장치는 아마 버퍼에 데이터를 쓸 것이다. 그리고 버퍼가 다 차면 전체 버퍼는 한번에 빠른 장치로 전송된다. 버퍼 전송이 이루어지는 동안에도 느린 장치가 데이터를 쓰기 위해서 **더블 버퍼링**이 사용된다. ( 이러한 더블버퍼링은 렌더링에도 사용되는데 이는 스크린 버퍼를 마저 다 그리지 못한 상황에서 유저가 스크린 버퍼를 보는 것을 막는다. )            
- 데이터 전송 크기 차이. 버퍼는 특히 네트워킹 시스템에 사용되는데 이는 데이터 전송을 위해 메세지들을 더 작은 패킷으로 쪼개고, 패킷을 받은 후 다시 합친다.       
- **copy semantics**을 지원하기 위해. 예를들면 어플리케이션이 디스크 쓰기를 위한 요청할 때, 데이터는 유저 메모리 영역에서 커널 버퍼로 복사된다. 이때 어플리케이션은 디스크에 쓰기 요청을 보냈던 메모리 영역에 쓰기 동작을 여전히 수행할 수 있는데, 이 때 어플리케이션이 데이터를 써도 디스크로 전송되는 데이터는 디스크 쓰기 요청이 만들어졌을 때의 데이터이다. ( 그러니깐 커널 버퍼로 데이터를 임시로 복사한 후 디스크로 전송을 함으로서, 어플리케이션이 디스크에 쓰기로 했던 데이터를 덮어써도 디스크에 쓰여지는 데이터는 덮어쓴 데이터가 아니라 커널 버퍼로 옮겨두었던 데이터가 디스크에 쓰이기 때문에, 디스크 쓰기 요청을 한 후에도 해당 메모리에 다른 쓰기 동작을 해도 괜찮다는 것이다. )      

아래 사진은 장치별 데이터 전송 속도를 보여준다.            
![13_10_SunTransferRates](https://user-images.githubusercontent.com/33873804/134784989-73704267-460c-44b8-9142-3b219ed3bd62.jpg)                



**캐싱**               

   











